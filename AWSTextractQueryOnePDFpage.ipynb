{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install amazon-textract-caller --upgrade\n",
    "!python -m pip install amazon-textract-response-parser --upgrade \n",
    "!python -m pip install tabulate --upgrade\n",
    "!python -m pip install PyPDF4 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curent AWS Region. Use this to choose corresponding S3 bucket with sample content\n",
    "\n",
    "mySession = boto3.session.Session()\n",
    "awsRegion = mySession.region_name\n",
    "\n",
    "# Amazon Textract client\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import boto3\n",
    "from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "search_string1 = \"E-FILE\"\n",
    "search_string2 = \"EFILE\"\n",
    "\n",
    "bucket_name = \"somename\"\n",
    "prefix = \"uploads/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "for obj in response['Contents']:\n",
    "    if obj['Key'].endswith('.pdf'):\n",
    "        s3.download_file(bucket_name, obj['Key'], os.path.basename(obj['Key']))\n",
    "        print(os.path.basename(obj['Key']))\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        with open(filename, 'rb') as pdf_file:\n",
    "            num_pages = PdfFileReader(pdf_file).getNumPages()\n",
    "            found_pages = []\n",
    "            for page_num in range(num_pages):\n",
    "                page = PdfFileReader(pdf_file).getPage(page_num)\n",
    "                page_text = page.extractText()\n",
    "                if re.search(search_string1 + '|' + search_string2, page_text):\n",
    "                    found_pages.append(page_num)\n",
    "            if found_pages:\n",
    "                pdf_writer = PdfFileWriter()\n",
    "                for page_num in found_pages:\n",
    "                    page = PdfFileReader(pdf_file).getPage(page_num)\n",
    "                    pdf_writer.addPage(page)\n",
    "                    output_filename = f\"{filename[:-4]}_page{page_num+1}.pdf\"\n",
    "                    with open(output_filename, \"wb\") as output_file:\n",
    "                        pdf_writer.write(output_file)\n",
    "                    s3.upload_file(output_filename, bucket_name, output_filename)\n",
    "                    os.remove(output_filename)\n",
    "            else:\n",
    "                print(f\"No instances of '{search_string1}' or '{search_string2}' found in {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startJob(s3BucketName, objectName):\n",
    "    response = None\n",
    "    response = textract.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': s3BucketName,\n",
    "            'Name': objectName\n",
    "        }\n",
    "    },\n",
    " FeatureTypes=[\"QUERIES\"],\n",
    "    QueriesConfig={\n",
    "            \"Queries\": [\n",
    "                {\n",
    "                \"Text\": \"what is in 'F Partner's name, address, city, state, and ZIP code'??\",\n",
    "                \"Pages\" : [\"*\"],    \n",
    "                \"Alias\": \"NAME_ADDRESS\"\n",
    "            },\n",
    "                {\n",
    "                \"Text\": \"What is the year?\",\n",
    "                \"Pages\" : [\"*\"],\n",
    "                \"Alias\": \"YEAR\"\n",
    "            },\n",
    "                {\n",
    "                \"Text\": \"What is the partnership name?\",\n",
    "                \"Pages\" : [\"*\"],\n",
    "                \"Alias\": \"PARTNERSHIP_NAME\"\n",
    "            },\n",
    "                {\n",
    "                \"Text\": \"What is the partnership address?\",\n",
    "                \"Pages\" : [\"*\"],\n",
    "                \"Alias\": \"PARTNERSHIP_ADDRESS\"\n",
    "            },\n",
    "            ]}\n",
    "    \n",
    "    )\n",
    "\n",
    "    return response[\"JobId\"]\n",
    "\n",
    "def isJobComplete(jobId):\n",
    "    response = textract.get_document_analysis(JobId=jobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Job status: {}\".format(status))\n",
    "\n",
    "    while(status == \"IN_PROGRESS\"):\n",
    "        time.sleep(5)\n",
    "        response = textract.get_document_analysis(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    "        print(\"Job status: {}\".format(status))\n",
    "\n",
    "    return status\n",
    "\n",
    "def getJobResults(jobId):\n",
    "\n",
    "    pages = []\n",
    "    response = textract.get_document_analysis(JobId=jobId)\n",
    "    \n",
    "    pages.append(response)\n",
    "   # print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    \n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        print(\"Yes\")\n",
    "        nextToken = response['NextToken']\n",
    "        print(response['NextToken'])\n",
    "\n",
    "    while(nextToken):\n",
    "        response = textract.get_document_analysis(JobId=jobId, NextToken=nextToken)\n",
    "\n",
    "        pages.append(response)\n",
    "        print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "    \n",
    "    with open(f'OutputResponse1.json', 'w') as json_file:\n",
    "        json.dump(response, json_file)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trp.trp2 as t2 \n",
    "from tabulate import tabulate\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "\n",
    "# Amazon S3 client\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = \"somename\"\n",
    "s3BucketName = \"somename\"\n",
    "\n",
    "my_bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "for object_summary in my_bucket.objects.filter():\n",
    "    if object_summary.key.endswith('.pdf'):\n",
    "        print(object_summary.key)\n",
    "        documentName = object_summary.key\n",
    "        jobId = startJob(s3BucketName, documentName)\n",
    "        print(\"Started job with id: {}\".format(jobId))\n",
    "        if(isJobComplete(jobId)):\n",
    "            response = getJobResults(jobId)\n",
    "            print(dir(response))\n",
    "            d = t2.TDocumentSchema().load(response)\n",
    "            #  print(len(d.pages))\n",
    "            for pageIndex in range(len(d.pages)):\n",
    "                page = d.pages[pageIndex]\n",
    "                query_answers = d.get_query_answers(page=page)\n",
    "                print(tabulate(query_answers, tablefmt=\"github\"))\n",
    "\n",
    "                csv_output = StringIO()\n",
    "                with open('outputfile.csv', 'a') as csv_file:\n",
    "                    csv_writer_file = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    for qa in query_answers:\n",
    "                        if len(qa[2]) > 0:\n",
    "                            csv_writer_file.writerow([documentName,qa[1], qa[2]])\n",
    "\n",
    "print(\"Process completed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
